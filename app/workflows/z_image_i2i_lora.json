{
  "9": {
    "inputs": {
      "images": [
        "43",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "$output.result"
    }
  },
  "39": {
    "inputs": {
      "clip_name": "qwen_3_4b.safetensors",
      "type": "lumina2",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "$clip_name"
    }
  },
  "40": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "$vae_name"
    }
  },
  "42": {
    "inputs": {
      "conditioning": [
        "45",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "43": {
    "inputs": {
      "samples": [
        "44",
        0
      ],
      "vae": [
        "40",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "44": {
    "inputs": {
      "seed": 0,
      "steps": 9,
      "cfg": 1,
      "sampler_name": "res_multistep",
      "scheduler": "simple",
      "denoise": 0.67,
      "model": [
        "47",
        0
      ],
      "positive": [
        "45",
        0
      ],
      "negative": [
        "42",
        0
      ],
      "latent_image": [
        "50",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Sampler, $seed, $steps, $cfg, $sampler_name, $scheduler, $denoise"
    }
  },
  "45": {
    "inputs": {
      "text": "A beautiful landscape",
      "clip": [
        "39",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "$prompt.text!"
    }
  },
  "46": {
    "inputs": {
      "unet_name": "z_image_turbo_bf16.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "$unet_name"
    }
  },
  "47": {
    "inputs": {
      "shift": 3,
      "model": [
        "52",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSampling, $shift"
    }
  },
  "49": {
    "inputs": {
      "image": "input.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "$image"
    }
  },
  "50": {
    "inputs": {
      "pixels": [
        "55",
        0
      ],
      "vae": [
        "40",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "52": {
    "inputs": {
      "lora_name": "example.safetensors",
      "strength_model": 1,
      "model": [
        "46",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "$lora_name, $lora_strength.strength_model"
    }
  },
  "55": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 2,
      "image": [
        "49",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "Scale, $megapixels"
    }
  }
}